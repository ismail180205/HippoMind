<p align="center">
  <img src="https://img.shields.io/badge/HippoMind-Reconstructive%20Memory-9966CC?style=for-the-badge&logo=brain&logoColor=white" alt="HippoMind" />
</p>

<h1 align="center">ğŸ§  HippoMind</h1>

<p align="center">
  <strong>A Reconstructive-Memory File Finder powered by AI</strong><br/>
  <em>Find half-remembered files through interactive memory reconstruction â€” not keyword search.</em>
</p>

<p align="center">
  <a href="#-quick-start"><img src="https://img.shields.io/badge/Quick%20Start-Guide-blue?style=flat-square" /></a>
  <a href="#-architecture"><img src="https://img.shields.io/badge/Architecture-Docs-green?style=flat-square" /></a>
  <a href="#-technology-stack"><img src="https://img.shields.io/badge/Tech%20Stack-Details-orange?style=flat-square" /></a>
  <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=flat-square&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/React-18-61DAFB?style=flat-square&logo=react&logoColor=black" />
  <img src="https://img.shields.io/badge/Qdrant-Vector%20DB-DC382D?style=flat-square" />
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square" />
</p>

---

## ğŸ”® The Problem & Our Solution

| Challenge                  | Impact                                                  | Our Solution                                                  |
| -------------------------- | ------------------------------------------------------- | ------------------------------------------------------------- |
| ğŸ—‚ï¸ **Vague Recall**        | You remember _something_ about a file but not its name  | Reconstructive memory search â€” describe what you recall       |
| ğŸ”— **Hidden Connections**  | Related documents are scattered and disconnected        | Automated clustering into meaningful topic groups             |
| â“ **Black Box Search**    | Traditional search returns ranked lists with no context | Interactive cluster exploration with LLM-generated labels     |
| ğŸ§© **Fragmented Memory**   | Keyword search fails when you can't recall exact terms  | LLM query expansion + hybrid dense/sparse retrieval           |
| ğŸ§­ **No Guided Discovery** | Search is one-shot â€” no progressive refinement          | Multi-round narrowing with follow-up questions & backtracking |
| ğŸ§  **No Spatial Context**  | Files exist as flat lists with no visual structure      | 3D brain visualization mapping documents to memory nodes      |

---

## ğŸ¬ Demo & Resources

### ğŸ¥ How It Works

> _"I remember a document about flooding in East Africaâ€¦ something about exposure methodologyâ€¦"_

Instead of searching for exact keywords, HippoMind lets you **describe your memory** â€” then progressively narrows down candidates through interactive clustering, follow-up questions, and visual exploration until your file is found. ğŸ¯

### ğŸ–¥ï¸ Screenshots

#### ğŸ§  3D Brain Visualization

> Interactive 3D graph of memory nodes using Three.js â€” documents are mapped to a neural topology. Drag to rotate, click to explore, scroll to zoom.

#### ğŸ” Cluster Search Interface

> When searching, documents cluster into labeled groups. Pick the group that matches your memory, and HippoMind dives deeper.

#### ğŸ“Š Navigation Tree

> A visual breadcrumb trail of your search journey â€” backtrack to any previous branch point and explore alternate paths.

#### ğŸ“ Data Panel

> Left sidebar showing files, images, and metadata for the selected memory node.

---

## ğŸ—ï¸ Architecture

### ğŸ“ System Overview

HippoMind follows a two-tier architecture â€” a **FastAPI backend** for AI-powered search and a **React frontend** for immersive visualization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        React Frontend                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DataPanel    â”‚  â”‚ BrainVisualizationâ”‚  â”‚  QueryInterface       â”‚ â”‚
â”‚  â”‚  (sidebar)    â”‚  â”‚ (Three.js 3D)    â”‚  â”‚  (search + clusters)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                     â”‚  SearchGraph     â”‚                            â”‚
â”‚                     â”‚  (nav tree SVG)  â”‚                            â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚  REST API (HTTP)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FastAPI Backend                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  api.py     â”‚  â”‚ search.py  â”‚  â”‚ config.pyâ”‚  â”‚  watcher.py    â”‚  â”‚
â”‚  â”‚  (routes)   â”‚  â”‚ (core AI)  â”‚  â”‚ (config) â”‚  â”‚  (PDF ingest)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚               â”‚                                â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Shared Services                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Qdrant Cloud â”‚  â”‚ BGE-large    â”‚  â”‚  Ollama (Gemma 3)   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ (vectors)    â”‚  â”‚ (embeddings) â”‚  â”‚  (labelling/expand) â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§© Core Components

| Component           | Technology                | Purpose                                                   |
| ------------------- | ------------------------- | --------------------------------------------------------- |
| **Frontend UI**     | React 18 + Three.js       | 3D brain visualization, search interface, navigation tree |
| **API Server**      | FastAPI + Uvicorn         | Session-based search flow, file serving, category tree    |
| **Search Engine**   | HDBSCAN + Ollama          | Hybrid retrieval, clustering, LLM labelling & follow-ups  |
| **PDF Ingestor**    | pdfplumber + LangChain    | Continuous file watcher, chunking, embedding, indexing    |
| **Vector Store**    | Qdrant Cloud              | Dense (BGE-large 1024d) + Sparse (BM25) hybrid storage    |
| **Embedding Model** | BAAI/bge-large-en-v1.5    | 1024-dim dense embeddings for semantic similarity         |
| **Sparse Model**    | Qdrant/bm25               | BM25 sparse vectors for keyword-level matching            |
| **LLM**             | Ollama (gemma3:4b-it-qat) | Query expansion, cluster labelling, follow-up questions   |

---

## âš¡ Reconstructive Memory Search: How It Works

### ğŸ¤” The Problem with Traditional File Search

Traditional search requires you to remember **exact keywords**, filenames, or metadata. But human memory is **reconstructive** â€” we recall fragments, associations, and feelings, not precise strings.

> _"That PDF aboutâ€¦ flooding? In Africa somewhere? It had a methodology sectionâ€¦"_

Standard search fails here. HippoMind succeeds.

### ğŸ’¡ Our Solution: Interactive Memory Reconstruction

HippoMind mirrors how the **hippocampus** works â€” reconstructing memories through **progressive association** rather than exact lookup.

### ğŸ”¬ How It Works

```
1ï¸âƒ£  User describes their memory
        â†“
2ï¸âƒ£  LLM expands the vague query (adds synonyms, related terms)
        â†“
3ï¸âƒ£  Hybrid search: Dense (BGE-large) + Sparse (BM25) â†’ RRF fusion
        â†“
4ï¸âƒ£  If direct match (â‰¥85% score) â†’ return immediately ğŸ¯
        â†“
5ï¸âƒ£  Otherwise, HDBSCAN clusters the results
        â†“
6ï¸âƒ£  Ollama labels each cluster with human-readable descriptions
        â†“
7ï¸âƒ£  User picks the cluster that "sounds right"
        â†“
8ï¸âƒ£  Repeat (narrow â†’ re-cluster â†’ pick) until one file remains
        â†“
    ğŸ¯ Found!
```

### ğŸ”„ Fallback: Follow-up Questions

When clustering can't differentiate, HippoMind switches to **guided Q&A**:

- The LLM generates memory-jogging questions based on remaining candidates
- User answers filter the candidate set semantically
- Up to 3 follow-up questions before forcing a result

### ğŸŒ³ Navigation Tree & Backtracking

Every choice creates a **navigation tree**. Users can:

- **See** their entire search journey as a branching graph
- **Backtrack** to any previous decision point
- **Explore alternative branches** without starting over

### ğŸ§ª Example Search Flow

```
Query: "flood exposure methodology"

  ğŸŒ Root: "flood exposure methodology"
  â”œâ”€â”€ ğŸŸ£ Cluster 0: "Somalia Flood Risk Assessment"        â† picked!
  â”‚   â”œâ”€â”€ ğŸ”µ Cluster 0: "Exposure Methodology Notes"       â† picked!
  â”‚   â”‚   â””â”€â”€ ğŸ¯ Found: Somalia_Flood_Exposure-Methodology_Note.pdf
  â”‚   â””â”€â”€ ğŸ”µ Cluster 1: "Vulnerability Mapping Reports"
  â”œâ”€â”€ ğŸŸ£ Cluster 1: "Climate Change Impact Studies"
  â””â”€â”€ ğŸŸ£ Cluster 2: "Humanitarian Response Plans"
```

---

## ğŸ“š Vector Collections

| Collection         | Model                  | Dimensions   | Vectors         | Purpose                      |
| ------------------ | ---------------------- | ------------ | --------------- | ---------------------------- |
| ğŸ” `ai_minds_docs` | BAAI/bge-large-en-v1.5 | 1024 (dense) | Named: `dense`  | Semantic document similarity |
| ğŸ“ `ai_minds_docs` | Qdrant/bm25            | Sparse       | Named: `sparse` | Keyword-level BM25 matching  |

### Chunk Types per Document

Each PDF generates **three types of vectors**:

| Type      | Content                                                             | Signal                         |
| --------- | ------------------------------------------------------------------- | ------------------------------ |
| `title`   | Friendly filename (e.g., "Somalia Flood Exposure Methodology Note") | Filename-level matching        |
| `summary` | LLM-generated 2-3 sentence summary                                  | Document-level semantic signal |
| `content` | 500-char overlapping text chunks                                    | Fine-grained passage retrieval |

---

## ğŸ› ï¸ Technology Stack

### ğŸ¨ Frontend

| Technology    | Version      | Purpose                      |
| ------------- | ------------ | ---------------------------- |
| React         | ^18.2.0      | UI library                   |
| Three.js      | Custom hooks | 3D brain graph visualization |
| Lucide React  | ^0.263.1     | Icon library                 |
| React Scripts | 5.0.1        | Build toolchain (CRA)        |

### âš™ï¸ Backend â€” API Server (FastAPI)

| Technology | Version | Purpose                               |
| ---------- | ------- | ------------------------------------- |
| FastAPI    | Latest  | REST API framework with async support |
| Uvicorn    | Latest  | ASGI server                           |
| Pydantic   | v2      | Request/response validation           |
| Python     | 3.10+   | Runtime                               |

### ğŸ”® Search & AI Pipeline

| Technology            | Version | Purpose                                              |
| --------------------- | ------- | ---------------------------------------------------- |
| Qdrant Client         | Latest  | Vector database client                               |
| Sentence Transformers | Latest  | Dense embeddings (BGE-large-en-v1.5, 1024-dim)       |
| FastEmbed             | Latest  | Sparse BM25 embeddings                               |
| HDBSCAN               | Latest  | Density-based clustering                             |
| Ollama                | Latest  | Local LLM for query expansion, labelling, follow-ups |
| NumPy                 | Latest  | Vector operations & normalization                    |

### ğŸ“„ Document Processing

| Technology               | Version | Purpose                                         |
| ------------------------ | ------- | ----------------------------------------------- |
| pdfplumber               | Latest  | PDF text extraction                             |
| LangChain Text Splitters | Latest  | Recursive text chunking (500 chars, 50 overlap) |
| Pandas                   | Latest  | Data manipulation                               |

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

- **Python 3.10+**
- **Node.js 18+** and npm
- **Qdrant** instance (cloud or local via Docker)
- **Ollama** running locally with a model loaded
- **Groq API key** (optional, for cloud LLM)

### ğŸ“¥ Installation

#### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/ismail180205/HippoMind.git
cd HippoMind
```

#### 2ï¸âƒ£ Backend (FastAPI)

```bash
cd backend
pip install -r requirements.txt
```

Create a `.env` file:

```env
QDRANT_URL=https://your-cluster.cloud.qdrant.io:6333
QDRANT_API_KEY=your-api-key-here
QDRANT_COLLECTION=ai_minds_docs
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b-it-qat
DATA_DIR=./data
```

Start the API server:

```bash
python api.py
# â†’ Starts on http://localhost:8111
```

Start the PDF watcher (in a separate terminal):

```bash
python watcher.py
# â†’ Watches ./data/ for new PDFs
```

#### 3ï¸âƒ£ Frontend (React)

```bash
cd frontend
npm install
npm start
# â†’ Starts on http://localhost:3000, proxied to backend at :8111
```

#### 4ï¸âƒ£ Qdrant (if running locally)

```bash
docker run -p 6333:6333 qdrant/qdrant
```

Then set `QDRANT_URL=http://localhost:6333` in your `.env`.

#### 5ï¸âƒ£ Ollama (local LLM)

```bash
ollama pull gemma3:4b-it-qat
ollama serve
# â†’ Runs on http://localhost:11434
```

### âœ… Verify Installation

```bash
# Backend API
curl http://localhost:8111/health
# â†’ {"status": "ok"}

# Collection stats
curl http://localhost:8111/collection/stats
# â†’ {"collection": "ai_minds_docs", "points_count": ..., ...}

# Frontend
open http://localhost:3000
```

---

## ğŸ“š Usage Examples

### ğŸ”¬ Example 1: Ingesting Documents

Drop PDF files into the `backend/data/` folder. The watcher will automatically:

1. ğŸ“„ Extract text from each PDF via pdfplumber
2. âœ‚ï¸ Chunk the text (500 chars, 50 overlap)
3. ğŸ“ Generate an LLM summary of the document
4. ğŸ”¢ Embed with BGE-large (1024-dim dense) + BM25 (sparse)
5. ğŸ“¤ Push vectors + payloads to Qdrant

### ğŸ” Example 2: Searching via API

```python
import requests

# Start a search session
response = requests.post(
    "http://localhost:8111/search",
    json={"query": "flooding methodology East Africa"}
)
session = response.json()
print(f"ğŸ” Session: {session['session_id']}")
print(f"ğŸ“Š Status: {session['status']}")
print(f"ğŸ“ Files: {len(session['files'])} candidates")

# If status is "clusters", pick one
if session['status'] == 'clusters':
    for cluster in session['clusters']:
        print(f"  ğŸŸ£ [{cluster['id']}] {cluster['label']} "
              f"({cluster['size']} chunks, {len(cluster['files'])} files)")

    # Pick the most relevant cluster
    response = requests.post(
        f"http://localhost:8111/session/{session['session_id']}/pick",
        json={"cluster_id": session['clusters'][0]['id']}
    )
    updated = response.json()
    print(f"\nğŸ“Š New status: {updated['status']}")
```

**Output:**

```
ğŸ” Session: a3f2c9b1e8d4
ğŸ“Š Status: clusters
ğŸ“ Files: 15 candidates
  ğŸŸ£ [0] Somalia Flood Risk & Exposure Assessment (42 chunks, 5 files)
  ğŸŸ£ [1] Climate Vulnerability Mapping Studies (28 chunks, 4 files)
  ğŸŸ£ [2] Humanitarian Response & Recovery Plans (19 chunks, 3 files)

ğŸ“Š New status: clusters  (narrowed to sub-clusters)
```

### ğŸ’­ Example 3: Using Follow-up Questions

```python
# When stuck, ask for a follow-up question
response = requests.post(
    f"http://localhost:8111/session/{session_id}/help",
    json={}
)
session = response.json()
print(f"â“ {session['pending_question']}")
# â†’ "Does the document you're looking for focus more on
#     statistical methodology or field survey results?"

# Answer the question
response = requests.post(
    f"http://localhost:8111/session/{session_id}/answer",
    json={"answer": "It was about statistical methodology, exposure calculations"}
)
result = response.json()
print(f"ğŸ“Š Status: {result['status']}")
# â†’ "found" ğŸ¯
print(f"ğŸ¯ File: {result['found_file']}")
```

### ğŸŒ³ Example 4: Backtracking

```python
# View the navigation tree
session = requests.get(f"http://localhost:8111/session/{session_id}").json()
for node in session['nav_tree']:
    indent = "  " * node['depth']
    marker = "â†’" if node['isOnPath'] else " "
    print(f"{indent}{marker} [{node['nodeId']}] {node['label']}")

# Backtrack to explore a different branch
requests.post(
    f"http://localhost:8111/session/{session_id}/backtrack",
    json={"node_id": "c1-r1"}  # go back to cluster 1 from round 1
)
```

---

## ğŸ§© API Reference

| Method   | Endpoint                  | Description                         |
| -------- | ------------------------- | ----------------------------------- |
| `GET`    | `/health`                 | Health check                        |
| `GET`    | `/collection/stats`       | Qdrant collection metadata          |
| `GET`    | `/categories`             | Brain-node category tree for 3D viz |
| `GET`    | `/categories/{id}/data`   | Images & files for a specific node  |
| `GET`    | `/query-options`          | Available query actions             |
| `POST`   | `/search`                 | Start a new search session          |
| `GET`    | `/session/{id}`           | Get current session state           |
| `POST`   | `/session/{id}/pick`      | Pick a cluster to narrow down       |
| `POST`   | `/session/{id}/help`      | Request a follow-up question        |
| `POST`   | `/session/{id}/answer`    | Answer a follow-up question         |
| `POST`   | `/session/{id}/backtrack` | Backtrack to a previous nav node    |
| `DELETE` | `/session/{id}`           | Delete a session                    |
| `GET`    | `/files/recent`           | Recently indexed files              |
| `GET`    | `/files/timeline`         | Files organized by date             |
| `GET`    | `/files/thumbnail`        | Serve image thumbnail               |
| `GET`    | `/files/download`         | Download a file                     |
| `GET`    | `/files/preview`          | Preview a file inline               |
| `POST`   | `/cache/invalidate`       | Force-refresh categories cache      |

---

## ğŸ“– Documentation

| ğŸ“‚ Component       | ğŸ“„ File                                          | Description                                         |
| ------------------ | ------------------------------------------------ | --------------------------------------------------- |
| ğŸ§  Backend API     | `backend/api.py`                                 | FastAPI server â€” sessions, search, file serving     |
| ğŸ” Search Engine   | `backend/search.py`                              | Hybrid retrieval, HDBSCAN clustering, LLM labelling |
| ğŸ“„ PDF Watcher     | `backend/watcher.py`                             | Continuous file ingest pipeline                     |
| âš™ï¸ Configuration   | `backend/config.py`                              | All environment variables & defaults                |
| ğŸ¨ Frontend App    | `frontend/src/App.jsx`                           | Main React app â€” state orchestration                |
| ğŸ§  3D Brain        | `frontend/src/components/BrainVisualization.jsx` | Three.js 3D graph                                   |
| ğŸŒ³ Search Graph    | `frontend/src/components/SearchGraph.jsx`        | Navigation tree (SVG)                               |
| ğŸ” Query Interface | `frontend/src/components/QueryInterface.jsx`     | Search input + cluster selection                    |
| ğŸ“Š Data Panel      | `frontend/src/components/DataPanel.jsx`          | File/image sidebar                                  |
| ğŸ”Œ API Service     | `frontend/src/services/api.js`                   | Frontend â†” Backend HTTP client                      |
| ğŸ—ï¸ Architecture    | `frontend/ARCHITECTURE.md`                       | Component tree, data flow, event flow               |

---

## âš™ï¸ Configuration

All settings live in `backend/config.py` and can be overridden via environment variables:

| Variable                   | Default                  | Description                         |
| -------------------------- | ------------------------ | ----------------------------------- |
| `QDRANT_URL`               | â€” (required)             | Qdrant server URL                   |
| `QDRANT_API_KEY`           | â€” (required)             | Qdrant API key                      |
| `QDRANT_COLLECTION`        | `ai_minds_docs`          | Collection name                     |
| `DATA_DIR`                 | `./data`                 | Folder to watch for PDFs            |
| `OLLAMA_BASE_URL`          | `http://localhost:11434` | Ollama server URL                   |
| `OLLAMA_MODEL`             | `gemma3:4b-it-qat`       | LLM model for labelling & expansion |
| `EMBEDDING_MODEL`          | `BAAI/bge-large-en-v1.5` | Dense embedding model (1024-dim)    |
| `SPARSE_MODEL`             | `Qdrant/bm25`            | Sparse embedding model              |
| `CHUNK_SIZE`               | `500`                    | Text chunk size (characters)        |
| `CHUNK_OVERLAP`            | `50`                     | Chunk overlap                       |
| `HDBSCAN_MIN_CLUSTER_SIZE` | `5`                      | Minimum cluster size                |
| `DIRECT_MATCH_THRESHOLD`   | `0.85`                   | Score threshold for immediate match |
| `SEARCH_TOP_K`             | `100`                    | Number of results per search leg    |
| `DENSE_WEIGHT`             | `0.7`                    | Weight for dense vectors in fusion  |
| `SPARSE_WEIGHT`            | `0.3`                    | Weight for sparse vectors in fusion |

---

## ğŸ¯ Core Principles

### ğŸ§  Reconstructive Memory

Human memory is associative, not indexed. HippoMind mirrors the hippocampus â€” reconstructing context through progressive narrowing, not exact matching.

### ğŸ” Hybrid Retrieval

Dense semantics (BGE-large) catch meaning; sparse BM25 catches keywords. RRF fusion combines both for robust recall.

### ğŸ§© Interactive Clustering

HDBSCAN discovers natural topic groups. LLM-generated labels make them human-readable. Users navigate by recognition, not recall.

### ğŸŒ³ Explorable Search

Every search creates a tree. Users can backtrack, branch, and explore â€” search is a journey, not a one-shot query.

---

## ğŸŒŸ What Makes HippoMind Unique?

| Feature           | Traditional Search      | HippoMind                                |
| ----------------- | ----------------------- | ---------------------------------------- |
| **Query Type**    | Exact keywords required | Vague, fragmentary descriptions          |
| **Search Flow**   | One-shot â†’ ranked list  | Multi-round interactive narrowing        |
| **Understanding** | "15 results found"      | "These cluster around flood methodology" |
| **When Stuck**    | Try different keywords  | LLM asks memory-jogging follow-ups       |
| **Navigation**    | Linear results list     | Branching tree with backtracking         |
| **Visualization** | Flat file list          | 3D brain graph with spatial memory       |
| **Retrieval**     | Dense OR keyword        | Hybrid dense + sparse RRF fusion         |
| **Indexing**      | Filename + full-text    | Title + LLM summary + content chunks     |

---

## ğŸ“‚ Project Structure

```
HippoMind/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py              # FastAPI server â€” sessions, search, file serving
â”‚   â”œâ”€â”€ search.py           # Hybrid retrieval, HDBSCAN, LLM labelling
â”‚   â”œâ”€â”€ watcher.py          # Continuous PDF ingest pipeline
â”‚   â”œâ”€â”€ config.py           # All settings (env vars)
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ data/               # Drop PDFs here â†’ auto-indexed
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ ARCHITECTURE.md     # Component tree & data flow docs
â”‚   â”œâ”€â”€ package.json        # Node dependencies
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx                         # Main app â€” state orchestration
â”‚       â”œâ”€â”€ App.css
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ BrainVisualization.jsx/css   # 3D brain graph (Three.js)
â”‚       â”‚   â”œâ”€â”€ SearchGraph.jsx/css          # Navigation tree (SVG)
â”‚       â”‚   â”œâ”€â”€ QueryInterface.jsx/css       # Search + cluster selection
â”‚       â”‚   â”œâ”€â”€ DataPanel.jsx/css            # File/image sidebar
â”‚       â”‚   â”œâ”€â”€ ImageGrid.jsx/css            # Image grid layout
â”‚       â”‚   â”œâ”€â”€ FileList.jsx/css             # File list layout
â”‚       â”‚   â””â”€â”€ QueryOption.jsx/css          # Query option button
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â”œâ”€â”€ useThreeScene.js             # Three.js scene lifecycle
â”‚       â”‚   â””â”€â”€ useFiringAnimation.js        # Neuron firing animation
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â””â”€â”€ memoryData.js                # Memory categories & options
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ api.js                       # Frontend â†” Backend HTTP client
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)** â€” state-of-the-art dense embedding model
- **[Qdrant](https://qdrant.tech)** â€” high-performance vector database with hybrid search
- **[Ollama](https://ollama.com)** â€” local LLM inference for privacy-first AI
- **[HDBSCAN](https://hdbscan.readthedocs.io)** â€” density-based clustering that finds natural topic groups
- **[Three.js](https://threejs.org)** â€” 3D graphics engine powering the brain visualization
- **[FastAPI](https://fastapi.tiangolo.com)** â€” modern Python web framework
- Open-source community for incredible tools â¤ï¸

---

## â“ Questions or Feedback?

Open an [issue](https://github.com/ismail180205/HippoMind/issues) or start a [discussion](https://github.com/ismail180205/HippoMind/discussions) if you have questions or want to contact us.

â­ **If you find HippoMind useful, please give us a star!**

---

<p align="center">
  Made with â¤ï¸ by the <strong>HippoMind Team</strong><br/>
  <em>Reconstructing memories through AI â€” because you don't always remember filenames, but you always remember the feeling.</em>
</p>
